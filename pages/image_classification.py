import streamlit as st
import time
import torch
from PIL import Image
import requests
from io import BytesIO
from torchvision.models import resnet18
from models.model_1.preprocessing import preprocess    # –∑–¥–µ—Å—å –º—ã –∫–∞—Ä—Ç–∏–Ω–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏ –≤–ø–∏—Å—ã–≤–∞–µ–º –≤ –Ω—É–∂–Ω—ã–π –Ω–∞–º —Ä–∞–∑–º–µ—Ä


st.markdown(
    '<h1 style="text-align: center;">–ú–æ–¥–µ–ª—å, –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—é—â–∞—è –ø–æ–≥–æ–¥—É üêõ</h1>',
    unsafe_allow_html=True
)
st.write('**–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫—É (–∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑—á–∏–∫) –≤ –º–æ–¥–µ–ª—å. –ú–æ–¥–µ–ª—å –¥–∞–µ—Ç —Å–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–∫–∏.**')

uploaded_files = st.file_uploader('–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', type=['png', 'jpg', 'jpeg'], accept_multiple_files=True)
image_url = st.text_input('–ò–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ')

classes = ['dew üí¶','fogsmog üí®','frost ‚ùÑÔ∏è','glaze ‚õÑÔ∏è','hail üå®','lightning ‚ö°Ô∏è','rain üåß','rainbow üåà','rime ‚ùÑÔ∏è','sandstorm üå™','snow üå®']
image = None

if uploaded_files:
    image = []
    for uploaded_file in uploaded_files:
        img = Image.open(uploaded_file)
        image.append(img)
elif image_url:
    try:
        response = requests.get(image_url)
        image = Image.open(BytesIO(response.content))
    except Exception as e:
        st.error(f'–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ —Å—Å—ã–ª–∫–µ. –û—à–∏–±–∫–∞ {e}')
else:
    st.write('–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!')

@st.cache_resource()
def load_model():
    model = resnet18(pretrained=False)
    model.fc = torch.nn.Linear(model.fc.in_features, 11)
    model.load_state_dict(torch.load('models/model_1/resnet_weather_weights.pt', map_location=torch.device('cpu')))
    return model

model = load_model()     # —Å–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∞—Å—Å–∞
model.eval()

def predict(img):
    img = preprocess(img)
    pred = model(img)
    return pred


if image:

    start_time = time.time()

    if isinstance(image, list):
        for img in image:
            st.image(img, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ')
            # —Å—é–¥–∞ –≤—ã–∑—ã–≤–∞–µ–º –ø—Ä–µ–¥–∏–∫—Ç –º–æ–¥–µ–ª–∏
            prediction = predict(img)
            st.write(f'–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å:')
            st.markdown(f"""
            <h2 style='text-align: center; color:#3262a8; font-size: 30px; font-weight: bold; padding: 10px; bolder-radius:10px;'>
            {classes[prediction.argmax(axis=1).item()]}
            </h2>
            """, unsafe_allow_html=True)
    else:
        st.image(image, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ')
        # —Å—é–¥–∞ –≤—ã–∑—ã–≤–∞–µ–º –ø—Ä–µ–¥–∏–∫—Ç –º–æ–¥–µ–ª–∏
        prediction = predict(image)
        st.write(f'–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å:')
        st.markdown(f"""
        <h2 style='text-align: center; color:#3262a8; font-size: 30px; font-weight: bold; padding: 10px; bolder-radius:10px;'>
        {classes[prediction.argmax(axis=1).item()]}
        </h2>
        """, unsafe_allow_html=True)
    
    end_time = time.time()
    elapsed_time = end_time - start_time
    st.write('–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö:')
    st.markdown(f"""
    <h3 style='text-align: center; color:#3262a8; font-size: 30px; font-weight: bold; padding: 5px; bolder-radius:5px;'>
    {elapsed_time:.2f}
    </h3>
    """, unsafe_allow_html=True)

else:
    st.stop()

